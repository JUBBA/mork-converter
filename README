Mork Converter
Version 1.0
February 26, 2009
Kevin Goodsell

Preliminary Info
----------------
This project began with a misunderstanding. I wanted to convert my
Thunderbird mailboxes to a different format, and I mistakenly thought
that this would require reading the Mork-formatted .msf files. It turns
out that a .msf (mail summary file) file is only an index. I'm not sure
how I missed this, but that's beside the point.

There are a few existing tools to read (some) Mork files, but they fail
to read .msf files. I started writing my own tool, partly to experiment
with Python parsing using PLY (Python Lex-Yacc). In spite of my
realization that I had little or no real use for this tool, I decided to
continue working on it until it could be released in the hope that it
might be useful to others.

License
-------
This software is licensed under the MIT license. Read the LICENSE file
for details.

Contact
-------
If you find this useful or discover a problem with it, please let me
know. It was an interesting project to work on, but I'll probably only
update it if I hear that it's being used.

Email:
kevin-opensource@omegacrash.net

Prerequisites
-------------
* Python 2, version 2.4 or higher. Python 3 is not supported.
* PLY (Python Lex-Yacc). Version 2.5 was used during development. Other
  versions have not been tested.

Basic Usage
-----------
To read the Mork file history.dat and output an XML file called
mork.xml, use:

  mork history.dat

To do the same, but output to a file called history.xml, use:

  mork --format=xml:out=history.xml history.dat

To output to a set of CSV (Comma-Separated Values) files, one for each
table and meta-table in the Mork database, use:

  mork --format=csv history.dat

This will write the output files into a directory called csvout. You can
also write a single file with a header before each table by doing this:

  mork --format=csv:singlefile history.dat

This will still use the name csvout, but it will be a file rather than a
directory.

For additional help, use:

  mork --help

About Mork Files
----------------
Mork is a general-purpose text-based database format created for use in
the Mozilla project. I know of four specific ways it has been used in
Mozilla and related projects (Firefox, Thunderbird):

* Browsing history
* Form history
* Address book
* Mailbox index

Unfortunately this format is rather convoluted and very difficult to
read, making the data contained in the database practically inaccessible
by non-Mozilla applications. Recently sqlite databases have replaced
Mork databases for some uses, largely alleviating this problem.

Mork represents data in tables. Tables are uniquely identified by a
namespace and ID. Tables include a set of rows and metadata in the form
of a 'meta-table'. Rows are likewise identified by a namespace and ID,
and may also include metadata in the form of a 'meta-row', however I
have not encountered any Mork files that make use of meta-rows. If this
tool encounters a meta-row it will report a warning and otherwise ignore
it. Row data is a set of key-value pairs where the keys are referred to
as columns.

The output from this tool depends on the output filter selected with the
--format option, but will typically contain a set of tables
corresponding to the tables in the Mork file, each identified by the
table namespace and ID. Each table's meta-table is also included, and
may contain information useful for interpreting the table contents.
Meta-tables seem to always contain a 'k' field that identifies the
'kind' of the table, and a 's' field that always seems to have the value
'9'.

Rows in a table are not uniform. Columns that appear in one row may not
appear in others. This makes the output a little odd, especially in
formats like CSV that require uniform rows. The result is that all
columns appear in the table header, and each row will have empty fields
for the columns that are not actually present in the row.

Each row is also identified by a namespace and ID, which typically shows
up in the output (as row attributes in XML and as extra columns in CSV).
This will probably not be useful other than for debugging, so you can
usually ignore it.

Filters
-------
This converter includes a basic framework for "filters", which are used
for writing output (output filters) and for tweaking the database prior
to output (database filters).

Available filters are shown in the --help output. Information on how to
write filters can be found in the doc/ subdirectory.

Output filters are specified with the --format option, and only one
output filter may be provided on the command line. Available output
filters include 'xml' and 'csv', for writing XML and CSV files,
respectively.

Database filters are specified with the --filter option. You may specify
as many as you'd like, and they are applied in the order they are given
on the command line. Available database filters include 'utf16', which
converts UTF-16 fields to UTF-8, and 'times' which converts fields that
represent times and dates to standard time formats.

There is also a 'nometa' filter, which removes meta-tables from the
database. This might come in handy for cases where the meta-tables do
not contain useful information, and just get in the way of interpreting
the output. Note, however, that the meta-tables might be necessary for
other filters to function properly. Because of this, the 'nometa' filter
should probably be the last filter applied.

Applying a filter more than once will probably not work correctly.

Known Issues
------------
* The Mork documentation I've been able to find is not quite adequate,
  so there's a significant amount of guess-work involved in the
  translation.
* Many errors are currently reported with Python tracebacks. This is not
  very user-friendly.
* The parsing is rather slow. This seems to be an inherent issue with
  PLY.
* Some Mork files include data that appears to be encoded in UTF-16
  mixed with ASCII or UTF-8 data. There's no indication (as far as I can
  tell) when a field is UTF-16. The 'utf16' filter attempts to correct
  this problem, but only applies to fields that are explicitly mentioned
  in the filter source. This list may be incomplete, causing some fields
  to be left in UTF-16.
* A similar warning applies for the 'times' filter: the fields to be
  converted have to be explicitly given in the filter source. In
  addition, I haven't verified the correctness of the resulting dates.
  It's possible that the fields in the Mork file don't represent times
  in the way that I think they do, as "UNIX time": seconds (or some
  other small time unit) since the epoch at January 1, 1970.
